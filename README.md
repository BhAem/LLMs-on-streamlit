# LLMs-on-streamlit
streamlit demo for chatting with LLMs using API

Use FastChat to building API for multiple LLMs

Can change the api to stream output

```streamlit run app.py```
